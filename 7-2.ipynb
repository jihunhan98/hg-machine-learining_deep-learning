{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "(train_input, train_target), (test_input, test_target) =\\\n",
    "keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 모델에 은닉층을 추가하는 방법 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dense1은 은닉층이 100개의 뉴런을 가진 밀집층. 활성화 함수는 sigmoid이며, 입력 데이터는 784*1 형태의 데이터를 입력받는다.\n",
    "\n",
    "은닉층의 뉴런 개수를 정하는 데에는 특별한 기준은 없다. 하지만 적어도 출력층의 뉴런보다는 많게 만들어야 한다.\n",
    "\n",
    "dense2는 10개의 클래스를 분류하므로, 10개의 뉴런을 두었고 활성화 함수는 softmax이다.\n",
    "\n",
    "위의 dense1과 dense2 객체를 Sequential 클래스에 추가하여 **심층 신경망**을 만들어 보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ([dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 모델에 은닉층을 추가하는 방법 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'), keras.layers.Dense(10, activation='softmax', name='output')]\n",
    ", name='패션 MNIST 모델')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 모델에 은닉층을 추가하는 방법 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax', input_shape=(784,), name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 985us/step - loss: 0.5661 - accuracy: 0.8088\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 957us/step - loss: 0.4087 - accuracy: 0.8527\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 905us/step - loss: 0.3746 - accuracy: 0.8648\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 916us/step - loss: 0.3519 - accuracy: 0.8721\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 916us/step - loss: 0.3346 - accuracy: 0.8790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0b2e856d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 분류 문제에서 높은 성능을 낼 수 있는 활성화 함수\n",
    "\n",
    "### 렐루 함수\n",
    "\n",
    "시그모이드 함수는 입력이 매우 크거나, 매우 작을 때 기울기가 매우 작아질 수 있다. 이 문제는 가중치를 업데이트 하는데 상당한 문제를 일으킬 수 있다.\n",
    "\n",
    "이를 개선하기 위하여 나온 함수가 렐루(ReLU) 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 Numpy배열을 reshape를 통하여 1차원으로 평탄화하였다. 하지만 지금은 keras 모델 자체에 Flatten 층을 추가하였으므로, reshape가 아닌, 28*28 형태의 데이터가 필요하다.\n",
    "\n",
    "다시 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input, train_target), (test_input, test_target) =\\\n",
    "keras.datasets.fashion_mnist.load_data()\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 914us/step - loss: 0.5370 - accuracy: 0.8106\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 909us/step - loss: 0.3953 - accuracy: 0.8566\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 913us/step - loss: 0.3571 - accuracy: 0.8707\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 904us/step - loss: 0.3359 - accuracy: 0.8801\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 936us/step - loss: 0.3197 - accuracy: 0.8849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0b2f6cf10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 688us/step - loss: 0.3731 - accuracy: 0.8787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37310147285461426, 0.8786666393280029]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD()\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 0.5328 - accuracy: 0.8143\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 932us/step - loss: 0.3991 - accuracy: 0.8581\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 957us/step - loss: 0.3553 - accuracy: 0.8712\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 901us/step - loss: 0.3258 - accuracy: 0.8807\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 953us/step - loss: 0.3075 - accuracy: 0.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0b2eebf70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 686us/step - loss: 0.3435 - accuracy: 0.8780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34353795647621155, 0.878000020980835]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eadcffed9d3c2393aa2c1e8af4faa14582bec2e5add70b0d0fc7cd41b2774778"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
